{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MIDS-W261-2015-HWK-Week01-Spooner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.0.0 Define big data. Provide an example of a big data problem in your domain of expertise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Data: Big data is the study and discipline of knowledge at the extreme large end of variety, velocity, or volume. Often two or all of these qualities will exist to a large degree. The exact size will vary over time as the term is relative to what is considered \"normal sized\" data. However, currently one might roughly think about big data variety in the dozens to hundreds of sources, big data velocity in terms of terrabytes per second, and big data volume in terms of petabytes.\n",
    "\n",
    "In my work domain of HMOs big data lies at the intersection of social media data being merged into health data, or live monitoring data such as blood pressure and heart rate into disease managment data. In these cases you take the already terrabytes of health data stored from insurance claims and are merging them with an enormous volume and velocity of streaming live data for the purpose of desease managment or near real time coordinated care services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.0.1 In 500 words (English or pseudo code or a combination) describe how to estimate the bias, the variance, the irreduciable error for a test dataset T when using polynomial regression models of degree 1, 2,3, 4,5 are considered. How would you select a model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias and variance are usually at odds. Bias is the difference between your model and the true model. Variance is the difference between your model and the data. If you reduce variance you'll over fit and introduce bias. If you try to fit your model to a idealized theoretical model which closely matches the true underlying function then you'll probably have to live with some variance as the data will rarely match 100%.\n",
    "\n",
    "Bias and variance can be estimated by looking at the difference between the regression models of 1 degree and the models of 5 degrees. A 5 degree model should have lower variance than bias. Depending on what assumptions you make about the true underlying function you might be able to conclude that the one degree model has less bias despite higher variance. \n",
    "\n",
    "Much of this is guesswork but looking at visual representations of the model and running sub-regressions may help deduce the underlying function. By choosing a model of the correct degrees that matches the general trend in the underlying data or intuitively matches the behavior of the underlying you can increase your chances of reducing both bias and variance.\n",
    "\n",
    "The most powerful tool however is using test and training data. Models trained on the training data are tested against the test data. Over fit models will have high variance when measured against the test data. Biased models will perform consistently off from the training data, although depending on the complexity of your data and model this consistent bias may be hard to isolate. Simplifying the data or isolating individual variables or interaction terms may permit you to find hidden trends not captured by your model that would create bias.\n",
    "\n",
    "Irreducible Error is the noise inherent in the data or measurement. Even the best most perfect model would never be able to get rid of this error, thus the \"irreducible\" part. Irreducible error can be estimated by calibrating your measurement devices against known standards. It can also be estimated by generating a high confidence model with simplified data and finding the variance remaining in this simplified high-confidence set. Your best model measured against the training data with best performance is your best way to estimate irreducible error in the absence of calibration.\n",
    "\n",
    "*Choosing the best Model:* Use test and training data. Depending on the size of your data set a half and half split may be appropriate. I'd want to save no less than 20% for test data. I'd begin by plotting the data and trying to get a general idea about its trends and shape. Then i would apply a function to train 5 polynomial regression models of degree 1 - 5. Then I'd test these models against the test data and examine their summary statistics in addition to plotting them to examine best fit. By comparing the test performance to the training performance I could estimate bias. If I had a very well fitting model which matches the trends in data when plotted I may be able to estimate the irreducible error by looking at the remaining test variance when using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.1 Read through the provided control script (pNaiveBayes.sh)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.2 Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh\n",
    "   will determine the number of occurrences of a single, user-specified word. Examine the word “assistance” and report your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "## mapper.py\n",
    "## Author: Spooner\n",
    "## Description: mapper code for HW1.2\n",
    "\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "## collect user input\n",
    "filename = sys.argv[1]\n",
    "findwords = re.split(\" \",sys.argv[2].lower())\n",
    "f = open(filename).read()\n",
    "words = re.split('\\s', f)\n",
    "count = 0\n",
    "for each in words:\n",
    "    if each in findwords:\n",
    "        count = count + 1\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## reducer.py\n",
    "## Author: Spooner\n",
    "## Description: mapper code for HW1.2\n",
    "\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "## collect mapper output and sum\n",
    "s = 0\n",
    "\n",
    "for each in range(1,len(sys.argv)):\n",
    "    f = open(sys.argv[each])\n",
    "    s = s + int(f.read())\n",
    "print s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#change permissions\n",
    "!chmod +x mapper.py; chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Git (version 1.8.4-preview20130916)\n",
      "\n",
      "\n",
      "Run 'git help git' to display the help index.\n",
      "Run 'git help <command>' to display help for specific commands.\n",
      "Mapper output: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run pNaiveBayes.sh\n",
    "!pNaiveBayes.sh 5 assistance\n",
    "\n",
    "f = open(\"enronemail_1h.txt.output\")\n",
    "print \"Mapper output: \" + f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.3 Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh\n",
    "   will classify the email messages by a single, user-specified word using the multinomial Naive Bayes Formulation. Examine the word “assistance” and report your results. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "## mapper.py\n",
    "## Author: Spooner\n",
    "## Description: mapper code for HW1.3\n",
    "\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "## collect user input\n",
    "filename = sys.argv[1]\n",
    "findwords = re.split(\" \",sys.argv[2].lower())\n",
    "f = open(filename).readlines()\n",
    "\n",
    "d = dict((key, [0,0,0,0]) for key in findwords)\n",
    "\n",
    "for key in d:\n",
    "    for line in f:\n",
    "        sets = re.split('\\t',line.lower())\n",
    "        #skip malformed lines\n",
    "        if len(sets) != 4:\n",
    "            continue\n",
    "        if sets[1] == '1':\n",
    "            #store total words in email\n",
    "            d[key][0] = d[key][0] + len(sets[2].split()) + len(sets[3].split())\n",
    "            for word in re.split(' ', sets[2]+sets[3]):\n",
    "                if word == key:\n",
    "                    d[key][1] = d[key][1] + 1\n",
    "        else:\n",
    "            d[key][2] = d[key][2] + len(sets[2].split()) + len(sets[3].split())\n",
    "            for word in re.split(' ', sets[2]+sets[3]):\n",
    "                if word in findwords:\n",
    "                    d[key][3] = d[key][3] + 1\n",
    "\n",
    "\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing parsing\n",
    "import re\n",
    "f = open(\"enronemail_1h.txt\").readlines()\n",
    "for line in f:\n",
    "    sets = re.split('\\t',line)\n",
    "    print sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## reducer.py\n",
    "## Author: Spooner\n",
    "## Description: mapper code for HW1.3\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import ast\n",
    "count = 0\n",
    "\n",
    "## collect mapper output and sum\n",
    "out = {}\n",
    "\n",
    "for each in range(1,len(sys.argv)):\n",
    "    f = open(sys.argv[each])\n",
    "    s = f.read()\n",
    "\n",
    "    d = ast.literal_eval(s)\n",
    "    for key in d:\n",
    "        if key not in out:\n",
    "            out[key] = [0,0,0,0]\n",
    "        out[key][0] = out[key][0] + d[key][0]\n",
    "        out[key][1] = out[key][1] + d[key][1]\n",
    "        out[key][2] = out[key][2] + d[key][2]\n",
    "        out[key][3] = out[key][3] + d[key][3]\n",
    "\n",
    "msg = ''\n",
    "for key in out:\n",
    "    msg = msg + '\\n' + key +': given spam: ' + str(out[key][1]*1.0/out[key][0]) + '\\n' + key +': given not spam: ' + str(out[key][3]*1.0/out[key][2]) \n",
    "    msg = msg + '\\n' + str(out[key])\n",
    "print msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[860, 0, 2894, 0]\n"
     ]
    }
   ],
   "source": [
    "# testing reducer parsing\n",
    "import ast\n",
    "f = open(\"enronemail_1h.txt.chunk.aa.counts\").read()\n",
    "d = ast.literal_eval(f)\n",
    "for key in d:\n",
    "    print d[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Git (version 1.8.4-preview20130916)\n",
      "\n",
      "\n",
      "Run 'git help git' to display the help index.\n",
      "Run 'git help <command>' to display help for specific commands.\n",
      "Mapper output: \n",
      "assistance: given spam: 0.000263490725126\n",
      "assistance: given not spam: 7.17566016073e-05\n",
      "[18976, 5, 13936, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run pNaiveBayes.sh\n",
    "!pNaiveBayes.sh 5 \"assistance\"\n",
    "\n",
    "f = open(\"enronemail_1h.txt.output\")\n",
    "print \"Mapper output: \" + f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.4 Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh\n",
    "   will classify the email messages by a list of one or more user-specified words. Examine the words “assistance”, “valium”, and “enlargementWithATypo” and report your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Git (version 1.8.4-preview20130916)\n",
      "\n",
      "\n",
      "Run 'git help git' to display the help index.\n",
      "Run 'git help <command>' to display help for specific commands.\n",
      "Mapper output: \n",
      "assistance: given spam: 0.000263490725126\n",
      "assistance: given not spam: 7.17566016073e-05\n",
      "[18976, 5, 13936, 1]\n",
      "enlargementwithatypo: given spam: 0.0\n",
      "enlargementwithatypo: given not spam: 7.17566016073e-05\n",
      "[18976, 0, 13936, 1]\n",
      "valium: given spam: 0.0\n",
      "valium: given not spam: 7.17566016073e-05\n",
      "[18976, 0, 13936, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I programmed the HW 1.3 code to work with multiple arguments\n",
    "!pNaiveBayes.sh 5 \"assistance valium enlargementWithATypo\"\n",
    "\n",
    "f = open(\"enronemail_1h.txt.output\")\n",
    "print \"Mapper output: \" + f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.5 Provide a mapper/reducer pair that, when executed by pNaiveBayes.sh\n",
    "   will classify the email messages by all words present.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancelled as per email from Instructor.  Smoothing covered in lesson 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 1.6 Benchmark your code with the Python SciKit-Learn implementation of multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cancelled as per email from Instructor. Smoothing covered in lesson 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
